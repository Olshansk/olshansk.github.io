---
title: "Intelligence is not intuition"
date: 2025-10-20T10:26:53-0700
draft: false
description: "AGI is here. AGi is not. No one is talking about it, and it will change everything."
tags: ["AI", "AGI", "AGi", "intuition", "Intelligence", "Posts"]
categories: ["AI", "Posts"]
medium_url: ""
substack_url: ""
ShowToc: true
TocOpen: false
ShowReadingTime: true
ShowBreadCrumbs: true
ShowPostNavLinks: true
ShowWordCount: true
---

Everyone's waiting for _Artificial General Intelligence (AGI)_.

The reality is that it's already here, and it hasn't changed a thing.

No one is talking about _Artificial General intuition (AGi)_ - yet.

When it arrives, it'll change everything.

{{< figure src="/images/agi-venn.png" alt="AGI Diagram" width="60%" class="center" >}}

## When will _AGi_ be here?

If you're reading this, you've most likely listened to Andrej Karpathy's conversation with Dwarkesh about [how AGI is still a decade away](https://www.dwarkesh.com/p/andrej-karpathy).

It's one of the highest _signal-to-noise_ conversations I've heard on the topic. But I'd argue that Artificial General Intelligence (AGI) is already here. Intuition is a decade away.

Whether you're using ChatGPT to draft an email, an online tool to generate videos, or a CLI-driven LLM agent to write code, we're using an **Artificial** tool in a **General** way that shows some degree of **Intelligence**. Sometimes I feel like people were more impressed by [Alex the parrot](<https://en.wikipedia.org/wiki/Alex_(parrot)>) than by the tools we're using today.

Billions of dollars (literally) are being poured into engineering efforts to move from intelligence to superintelligence, but the gap between superintelligence and intuition is where a new breakthrough is needed.

When (or if) it will happen is still an open question.

In the meantime, this distinction is critical because **intuition** is the key in utilizing Artificial General Intelligence to its full capacity.

## Non-intuitive Terminology Used in AI

I'll provide a short primer on the terminology used in the field of AI because it inadvertently highlights the difference between **intuition** and **intelligence**.

In [**Reinforcement Learning**](https://en.wikipedia.org/wiki/Reinforcement_learning), we use **reward functions** to **train** models to achieve specific goals. This is done through **learning** in either **supervised** or **unsupervised** ways. When the models are **applied** in the real world, we call it **inference**, which is just a fancy way of saying **prediction** based on past experience.

One could argue that the above is a form of intuition, but it still feels like something's missing. Intuition is not something that's taught, learned, trained, or built. It's something that's acquired over time.

## 10,000 hours

As I was thinking through this, I was reminded of [Malcolm Gladwell's famous 10,000-hour rule](https://pmc.ncbi.nlm.nih.gov/articles/PMC4662388/).

It's a great way to frame the difference between raw intelligence, experience, expertise, and intuition.

Most people haven't had their 10,000 hours with LLMs yet, and LLMs haven't had the equivalent of their 10,000 hours in the real world.

With a bit of effort, most people can be trained to do most things if there's a clear, repeatable process. It doesn't take 10,000 hours. In fact, I remember my first job at McDonald's as a 15-year-old. I was trained to salt french fries, and it only took an hour or so to get the hang of it üçü.

**What 10,000 hours gives you isn't just a tool, it's a toolbox and experience. Intuition is how you translate that experience to decide which tool to use given the circumstances.**

This reminds me of one of my favorite quotes by Pablo Picasso:

> ‚ÄúLearn the rules like a pro, so you can break them like an artist.‚Äù

## Intuition in AI vs. Intuition in Using AI

All of that is interesting, but how is any of it relevant today?

Understanding that LLMs, and in turn agents, are intelligent but not intuitive today is critical in understanding how to use them.

You build intuition for what they can and cannot do. You build intuition for when to take their results verbatim and when to question them. It's no different from hiring a brilliant and intelligent new graduate fresh out of college that hasn't built the intuition of how the corporate world operates.

**Remember, AI is intelligent but not intuitive. You are.**

## Concluding thoughts on what's next

We've built intelligence. Everyone‚Äôs racing toward Superintelligence. Some are even working on [Safe Superintelligence](https://ssi.inc/).

The next frontier is **Artificial General intuition**.

Intelligence scales logic. Intuition scales judgment. Judgment can't really be measured, it can only be acquired.

We don't yet know how we'll get there, but I'm excited to help create it.

---

If you enjoyed this, you can [subscribe to my Substack](https://olshansky.substack.com), follow [my RSS feed](https://olshansky.info/index.xml), or join my email list for those really special updates:

{{< mailerlite >}}
