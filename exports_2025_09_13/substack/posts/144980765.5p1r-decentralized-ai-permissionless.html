<p><em>This is part of a series called "5 points &amp; 1 resource" (think tl;dr but 5p;1r). I summarize 5 key concepts that would have helped me learn, relearn, or refresh my knowledge of a topic or paper.</em></p><p><em>Today, I‚Äôm reviewing a paper I contributed to myself so I added a personal forward :)</em></p><div><hr></div><ul><li><p><a href="https://olshansky.substack.com/i/144980765/the-real-value-prop-of-a-permissionless-inference-network">The real value prop of a permissionless inference network</a></p></li><li><p><a href="https://olshansky.substack.com/i/144980765/reference">1 Reference</a></p></li><li><p><a href="https://olshansky.substack.com/i/144980765/points">5 Points</a></p><ul><li><p>Point 1: POKT Network</p></li><li><p>Point 2: Model Suppliers</p></li><li><p>Point 3: POKT Network</p></li><li><p>Point 4: Model Providers</p></li><li><p>Point 5: Inference Verification</p></li></ul></li></ul><h2><strong>The real value prop of a permissionless inference network</strong></h2><p>Having spent more than half a decade working alongside some of the world‚Äôs leading ML researchers at Waymo &amp; Magic Leap, <a href="https://olshansky.substack.com/p/24-hours-of-chatgpt">I wrote about</a> how my worldview changed of what‚Äôs possible on <strong>December 1st, 2022</strong>. I use <a href="https://olshansky.substack.com/p/from-pc-personal-computer-to-pgpt">my personal GPT multiple times a day</a>, I <a href="https://x.com/olshansky/status/1682893635506012160">built a RAG</a> application before the term was coined, and I‚Äôve written about what practical eval entails as a result of my <a href="https://olshansky.substack.com/p/vibe-checks-are-all-you-need">prior experience and intuition</a>; <em>multiple ML researchers have told me offline that this is the hard truth no one wants to admit.</em></p><p>I frequently test different versions of <a href="https://ollama.com/library?q=llama">Llama on Ollama</a> but return to GPT-4 for high-quality responses. I experiment with various workflows with the goal of extending them to the whole team. The success-failure ratio is about 50-50 and I plan to detail these experiments here in the future.</p><div class="subscription-widget-wrap-editor" data-attrs="{&quot;url&quot;:&quot;https://olshansky.substack.com/subscribe?&quot;,&quot;text&quot;:&quot;Subscribe&quot;,&quot;language&quot;:&quot;en&quot;}" data-component-name="SubscribeWidgetToDOM"><div class="subscription-widget show-subscribe"><div class="preamble"><p class="cta-caption">If you‚Äôre a new reader, this feels like a good opportunity to prompt you (pun intended) to subscribe ‚ÄéüòÖ</p></div><form class="subscription-widget-subscribe"><input type="email" class="email-input" name="email" placeholder="Type your email‚Ä¶" tabindex="-1"><input type="submit" class="button primary" value="Subscribe"><div class="fake-input-wrapper"><div class="fake-input"></div><div class="fake-button"></div></div></form></div></div><p>Most of the AI industry and capital is mostly focused on building large, energy-consuming training clusters, often powered by NVIDIA, <em>the Nitro of GPUs</em>. However, my personal experience, combined with many conversations at various AI events has revealed the following:</p><ol><li><p><strong>Asynchronous, agentic or assistant-based tasks are not always limited by GPU power</strong>. Slower chatbot responses force me to think deeply about my prompt. It doesn't matter if an LLM that's assisting, teaching or reviewing something takes 60 seconds or 10 seconds. </p></li><li><p><strong>Costs can accumulate quickly</strong>. I use Llama3 locally for experiments but rely on GPT-4 APIs in "production." Iterations can cost $15 in 15 minutes or less. If OpenAI offered GPT-4 on cheaper hardware, at the cost of increased latency, I‚Äôd sign up.</p></li><li><p><strong>Experimentation is hard.</strong> Every time I want to try out a new model, I need to spend half an hour downloading a 50GB file only to learn that it‚Äôs ‚Äúbad‚Äù after doing a few <em>vibe checks</em>.  </p></li><li><p><strong>Energy</strong>. Some of my more complex local workflows make my M1 MacBook pro overheat to the point where I‚Äôm concerned about long-term damage, forgoing the battery life when I‚Äôm on the road.</p></li></ol><p>Our team at <a href="https://grove.city/">Grove</a> is piloting the expansion of <a href="https://pokt.network/">POKT Network</a> to support LLM inference. This isn't just a "Crypto x AI" narrative. It addresses cost, quality, energy, and enables both experimentation and incentivization. It's a permissionless network of hardware operators, that has been live for almost 4 years, offering high-quality services for blockchain RPC queries; <em>see the metrics <a href="https://poktscan.com/">here</a></em>. Gateways abstract protocol complexities, providing value (cost &amp; quality) with familiar SLAs. If an application doesn‚Äôt want to use a gateway, the onus of quality-of-service checks is on them.</p><p>The argument that scale is easier for centralized, vertically integrated companies is fair, but it comes with tradeoffs. There is a huge opportunity for idle mid-market GPUs to provide inference at a higher latency, but lower cost and satisfy many (not all) use cases. The <a href="https://arxiv.org/abs/2405.20450">litepaper we wrote</a> came out of a real need for this service, so it was the obvious next step in the evolution of the network we were already designing, building and growing.</p><p><strong>If you‚Äôre involved in maintaining cluster of mid-market GPUs which are sitting idle, this is a CALL TO ACTION to leave a comment and we‚Äôll make something happen.</strong></p><div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="https://substackcdn.com/image/fetch/$s_!YWl5!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Feffd77b3-2af1-48c7-9d60-36d18c87b97c_1024x1024.webp" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!YWl5!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Feffd77b3-2af1-48c7-9d60-36d18c87b97c_1024x1024.webp 424w, https://substackcdn.com/image/fetch/$s_!YWl5!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Feffd77b3-2af1-48c7-9d60-36d18c87b97c_1024x1024.webp 848w, https://substackcdn.com/image/fetch/$s_!YWl5!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Feffd77b3-2af1-48c7-9d60-36d18c87b97c_1024x1024.webp 1272w, https://substackcdn.com/image/fetch/$s_!YWl5!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Feffd77b3-2af1-48c7-9d60-36d18c87b97c_1024x1024.webp 1456w" sizes="100vw"><img src="https://substack-post-media.s3.amazonaws.com/public/images/effd77b3-2af1-48c7-9d60-36d18c87b97c_1024x1024.webp" width="464" height="464" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/effd77b3-2af1-48c7-9d60-36d18c87b97c_1024x1024.webp&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1024,&quot;width&quot;:1024,&quot;resizeWidth&quot;:464,&quot;bytes&quot;:566186,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/webp&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" class="sizing-normal" alt="" srcset="https://substackcdn.com/image/fetch/$s_!YWl5!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Feffd77b3-2af1-48c7-9d60-36d18c87b97c_1024x1024.webp 424w, https://substackcdn.com/image/fetch/$s_!YWl5!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Feffd77b3-2af1-48c7-9d60-36d18c87b97c_1024x1024.webp 848w, https://substackcdn.com/image/fetch/$s_!YWl5!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Feffd77b3-2af1-48c7-9d60-36d18c87b97c_1024x1024.webp 1272w, https://substackcdn.com/image/fetch/$s_!YWl5!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Feffd77b3-2af1-48c7-9d60-36d18c87b97c_1024x1024.webp 1456w" sizes="100vw" loading="lazy"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><div class="pencraft pc-reset icon-container restack-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-refresh-cw"><path d="M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8"></path><path d="M21 3v5h-5"></path><path d="M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16"></path><path d="M8 16H3v5"></path></svg></div><div class="pencraft pc-reset icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2 lucide-maximize-2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></div></div></a></figure></div><h2><strong>1 Reference</strong></h2><p>The one reference you need is just the https://arxiv.org/abs/2405.20450</p><p>https://arxiv.org/abs/2405.20450</p><h2><strong>5 Points</strong></h2><h5><strong>1. POKT Network - </strong>A mature protocol &amp; ecosystem primed to expand from web3 queries to LLM inference.</h5><ul><li><p>Handles <strong>500M daily requests</strong> with decentralized load balancing.</p></li><li><p>The <strong>Remote Procedure Call (RPC) abstraction</strong> is agnostic to the data being transported or compute being invoked.</p></li><li><p>LLM nodes are <strong>compute-heavy;</strong> Blockchain nodes are <strong>networking-heavy</strong>.</p></li><li><p>Unique value proposition: <strong>verifiable on-chain counter</strong> as a non-interactive optimistic rate limiter.</p></li></ul><h5><strong>2. </strong>Model Sources <strong>- AI researchers can monetize their open-source work by making it publicly available on the network.</strong></h5><ul><li><p>No need for backend infrastructure maintenance.</p></li><li><p>No need for front-end user-facing products.</p></li><li><p>Earnings are proportional to verified usage volume.</p></li></ul><h5><strong>3. Model Suppliers</strong>: Operators specialized in efficient hardware deployment &amp; maintenance.</h5><ul><li><p>Leverage both dedicated and idle hardware.</p></li><li><p>Ideal for temporarily idle NVIDIA GPUs or unused AMD (or other) GPUs not good enough for training.</p></li></ul><h5><strong>4. Model Providers</strong>: Gateways facilitate network access, abstracting out protocol </h5><ul><li><p>Provide permissionless quality-of-service, SLA guarantees, dashboards, value-add features, etc‚Ä¶</p></li><li><p>Can focus on things like routing requests to the best LLM, without expertise in hardware maintenance.</p></li></ul><h5><strong>5. Inference Verification</strong></h5><ul><li><p>This is a hard problem that has no silver bullet. POKT Network has a sufficiently good solution to it by aligning incentives and having Gateways (see <a href="https://www.grove.city/sla">Grove‚Äôs SLA</a>) provide enterprise grade customer support. That said, we have tons of ideas (see the screenshot below from the paper) that we‚Äôll iterate on in the years to come.</p></li></ul><div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="https://substackcdn.com/image/fetch/$s_!8jjk!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe129e1c8-d6ef-4764-9fa5-ba9709219e32_438x520.png" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!8jjk!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe129e1c8-d6ef-4764-9fa5-ba9709219e32_438x520.png 424w, https://substackcdn.com/image/fetch/$s_!8jjk!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe129e1c8-d6ef-4764-9fa5-ba9709219e32_438x520.png 848w, https://substackcdn.com/image/fetch/$s_!8jjk!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe129e1c8-d6ef-4764-9fa5-ba9709219e32_438x520.png 1272w, https://substackcdn.com/image/fetch/$s_!8jjk!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe129e1c8-d6ef-4764-9fa5-ba9709219e32_438x520.png 1456w" sizes="100vw"><img src="https://substack-post-media.s3.amazonaws.com/public/images/e129e1c8-d6ef-4764-9fa5-ba9709219e32_438x520.png" width="438" height="520" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/e129e1c8-d6ef-4764-9fa5-ba9709219e32_438x520.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:520,&quot;width&quot;:438,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:111994,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" class="sizing-normal" alt="" srcset="https://substackcdn.com/image/fetch/$s_!8jjk!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe129e1c8-d6ef-4764-9fa5-ba9709219e32_438x520.png 424w, https://substackcdn.com/image/fetch/$s_!8jjk!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe129e1c8-d6ef-4764-9fa5-ba9709219e32_438x520.png 848w, https://substackcdn.com/image/fetch/$s_!8jjk!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe129e1c8-d6ef-4764-9fa5-ba9709219e32_438x520.png 1272w, https://substackcdn.com/image/fetch/$s_!8jjk!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe129e1c8-d6ef-4764-9fa5-ba9709219e32_438x520.png 1456w" sizes="100vw" loading="lazy"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><div class="pencraft pc-reset icon-container restack-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-refresh-cw"><path d="M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8"></path><path d="M21 3v5h-5"></path><path d="M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16"></path><path d="M8 16H3v5"></path></svg></div><div class="pencraft pc-reset icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2 lucide-maximize-2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></div></div></a></figure></div>