<!DOCTYPE html><html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><title>An Incentive to Label</title><style>
      * {
        font-family: Georgia, Cambria, "Times New Roman", Times, serif;
      }
      html, body {
        margin: 0;
        padding: 0;
      }
      h1 {
        font-size: 50px;
        margin-bottom: 17px;
        color: #333;
      }
      h2 {
        font-size: 24px;
        line-height: 1.6;
        margin: 30px 0 0 0;
        margin-bottom: 18px;
        margin-top: 33px;
        color: #333;
      }
      h3 {
        font-size: 30px;
        margin: 10px 0 20px 0;
        color: #333;
      }
      header {
        width: 640px;
        margin: auto;
      }
      section {
        width: 640px;
        margin: auto;
      }
      section p {
        margin-bottom: 27px;
        font-size: 20px;
        line-height: 1.6;
        color: #333;
      }
      section img {
        max-width: 640px;
      }
      footer {
        padding: 0 20px;
        margin: 50px 0;
        text-align: center;
        font-size: 12px;
      }
      .aspectRatioPlaceholder {
        max-width: auto !important;
        max-height: auto !important;
      }
      .aspectRatioPlaceholder-fill {
        padding-bottom: 0 !important;
      }
      header,
      section[data-field=subtitle],
      section[data-field=description] {
        display: none;
      }
      </style></head><body><article class="h-entry">
<header>
<h1 class="p-name">An Incentive to Label</h1>
</header>
<section data-field="subtitle" class="p-summary">
tl;dr The incentive to label is to have a disincentive to label poorly
</section>
<section data-field="body" class="e-content">
<section name="d451" class="section section--body section--first"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h3 name="662f" id="662f" class="graf graf--h3 graf--leading graf--title">An Incentive to Label</h3><p name="6265" id="6265" class="graf graf--p graf-after--h3"><em class="markup--em markup--p-em">tl;dr The incentive to label is to have a disincentive to label poorly</em></p><p name="498c" id="498c" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">GPT4 Abstract</strong>: Large Language Models (LLMs) have made significant strides in recent years, thanks in part to Reinforcement Learning from Human Feedback (RLHF). However, the success of these models depends not only on the quantity of human labels but also on their quality. This blog post discusses the importance of high-quality labels in LLMs and proposes a blockchain-based solution to incentivize better labelling.</p><h3 name="e839" id="e839" class="graf graf--h3 graf-after--p">A Secret Ingredient</h3><p name="cc4f" id="cc4f" class="graf graf--p graf-after--h3">Large Language Models feel like they’ve been an overnight success these past few months. But, in reality, it’s the result of more than half a century of research, the increasing availability of scalable cloud compute, the advent of tons of online data, stirred together with the hard work of hundreds of people, thousands of optimizations and countless tweaks.</p><p name="554f" id="554f" class="graf graf--p graf-after--p">The special not-so-secret ingredient that tops all of it off is <a href="https://en.wikipedia.org/wiki/Reinforcement_learning_from_human_feedback" data-href="https://en.wikipedia.org/wiki/Reinforcement_learning_from_human_feedback" class="markup--anchor markup--p-anchor" rel="noopener noreferrer nofollow noopener" target="_blank">Reinforcement Learning From Human feedback (RLHF)</a>. Lex Fridman called it the “little magic ingredient” in a <a href="https://youtu.be/L_Guz73e6fw?t=363" data-href="https://youtu.be/L_Guz73e6fw?t=363" class="markup--anchor markup--p-anchor" rel="noopener noreferrer nofollow noopener" target="_blank">recent interview with Sam Altman</a>, and Chamath Palihapitiya called it the “White Truffle” in a <a href="https://youtu.be/qQ544sWC8ZQ?t=1349" data-href="https://youtu.be/qQ544sWC8ZQ?t=1349" class="markup--anchor markup--p-anchor" rel="noopener noreferrer nofollow noopener" target="_blank">recent episode of the All-In Podcast</a>. Just a little bit of RLHF sprinkled atop a massive amount of data and training is one of the significant differentiators that help with alignment and makes our newfound assistant so helpful in answering questions.</p><p name="73d3" id="73d3" class="graf graf--p graf-after--p">Here’s an example from Jan 2022 of how an older version of GPT3 performed before and after humans were in the loop.</p><figure name="487c" id="487c" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="0*FSa4ZZwE1hppEyEP.png" data-width="1456" data-height="832" src="https://cdn-images-1.medium.com/max/800/0*FSa4ZZwE1hppEyEP.png"><figcaption class="imageCaption"><a href="https://openai.com/research/instruction-following#sample1" data-href="https://openai.com/research/instruction-following#sample1" class="markup--anchor markup--figure-anchor" rel="noopener noreferrer nofollow noopener noopener" target="_blank">https://openai.com/research/instruction-following#sample1</a></figcaption></figure><p name="4a42" id="4a42" class="graf graf--p graf-after--figure">Despite all this work and advances, one crucial aspect that deserves more attention is the quality, not just the quantity, of human-generated labels used to align these models.</p><h3 name="a390" id="a390" class="graf graf--h3 graf-after--p">The Life of A Data Plumber</h3><p name="0175" id="0175" class="graf graf--p graf-after--h3">The unsexy truth everyone in the AI/ML industry knows is that most of your time will be spent doing data plumbing and filtering for high-quality labels. This infographic says it all.</p><figure name="c7b6" id="c7b6" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="0*Wrr70A2ZXNy4zL2W.png" data-width="913" data-height="611" src="https://cdn-images-1.medium.com/max/800/0*Wrr70A2ZXNy4zL2W.png"><figcaption class="imageCaption"><a href="https://twitter.com/schmarzo/status/1029948710254329856" data-href="https://twitter.com/schmarzo/status/1029948710254329856" class="markup--anchor markup--figure-anchor" rel="noopener noreferrer nofollow noopener noopener" target="_blank">@schmarzo</a></figcaption></figure><p name="d87e" id="d87e" class="graf graf--p graf-after--figure">Andrej Karaphy, who recently returned to OpenAI after a 5-year stint as Director of AI at Tesla, famously coined the term <a href="https://karpathy.medium.com/software-2-0-a64152b37c35" data-href="https://karpathy.medium.com/software-2-0-a64152b37c35" class="markup--anchor markup--p-anchor" rel="noopener noreferrer nofollow noopener" target="_blank">Software 2.0</a> in a 2017 blog post:</p><blockquote name="4e41" id="4e41" class="graf graf--blockquote graf-after--p"><em class="markup--em markup--blockquote-em">In most practical applications today, the neural net architectures and the training systems are increasingly standardized into a commodity, so most of the active “software development” takes the form of curating, growing, massaging and cleaning labeled datasets. This is fundamentally altering the programming paradigm by which we iterate on our software, as the teams split in two: the 2.0 programmers (data labelers) edit and grow the datasets, while a few 1.0 programmers maintain and iterate on the surrounding training code infrastructure, analytics, visualizations and labeling interfaces.</em></blockquote><p name="6a77" id="6a77" class="graf graf--p graf-after--blockquote">Now that LLMs can write a good portion of the code for us, this statement rings even more true than it did six years ago. However, with more than a dozen daily announcements related to new product launches using LLMs or optimizations to their performance, I’m hearing very few conversations about acquiring higher-quality human annotations. As someone who has seen the importance of smooth infrastructure and high-quality labels, I believe it will be one of the catalysts to seeing the next step function.</p><figure name="e48a" id="e48a" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="0*9iPyE8Y0lwtfrmB5.png" data-width="1219" data-height="700" src="https://cdn-images-1.medium.com/max/800/0*9iPyE8Y0lwtfrmB5.png"><figcaption class="imageCaption"><a href="https://karpathy.medium.com/software-2-0-a64152b37c35" data-href="https://karpathy.medium.com/software-2-0-a64152b37c35" class="markup--anchor markup--figure-anchor" rel="noopener noreferrer nofollow noopener noopener" target="_blank">https://karpathy.medium.com/software-2-0-a64152b37c35</a></figcaption></figure><h3 name="6d31" id="6d31" class="graf graf--h3 graf-after--figure">Augmented Reality — Boxes and Labels</h3><p name="967f" id="967f" class="graf graf--p graf-after--h3">At Magic Leap, we worked on a product called <a href="https://www.magicleap.com/spatial-mapping-ml1" data-href="https://www.magicleap.com/spatial-mapping-ml1" class="markup--anchor markup--p-anchor" rel="noopener noreferrer nofollow noopener" target="_blank">Shared World</a> that enabled multiplayer support through shared spatial mapping. The system also had an object recognition pipeline that used sensor data to understand the world around you. High-quality public databases such as <a href="https://www.image-net.org/" data-href="https://www.image-net.org/" class="markup--anchor markup--p-anchor" rel="noopener noreferrer nofollow noopener" target="_blank">ImageNet</a> were more than sufficient for this task.</p><p name="e94f" id="e94f" class="graf graf--p graf-after--p">Objective and well-defined questions, such as <em class="markup--em markup--p-em">“draw and label the animal in this photo</em>,” are arguably a solved problem. We already have large, high-quality, labeled data sets. In addition, a paper published last month showed that <a href="https://arxiv.org/pdf/2303.15056.pdf" data-href="https://arxiv.org/pdf/2303.15056.pdf" class="markup--anchor markup--p-anchor" rel="noopener noreferrer nofollow noopener" target="_blank">ChatGPT Outperforms Crowd-Workers for Text-Annotation Tasks</a> in terms of accuracy, time and cost, and I expect the same thing to extend to images in the near future.</p><p name="9756" id="9756" class="graf graf--p graf-after--p">Though much engineering work still needs to be done to make AR an everyday reality, there are many more nuanced open-ended problems in the AV space.</p><h3 name="583e" id="583e" class="graf graf--h3 graf-after--p">Autonomous Vehicles — Risky or Not?</h3><p name="6fa1" id="6fa1" class="graf graf--p graf-after--h3">While I was at Waymo on the Planner Evaluation team, one of the critical questions we tried to answer was: <em class="markup--em markup--p-em">Does this on-road (actual or simulated) situation pose a risk for a Vulnerable Road User (VRU)?</em></p><p name="4e3b" id="4e3b" class="graf graf--p graf-after--p">We were able to leverage Alphabet’s infrastructure and resources to collect thousands of labels but faced a ton of problems along the way. In particular, a lot of time was spent on training and evaluating labellers while accounting for cultural driving differences. It forced me to learn about the subtle differences in driving practices between the US and India…</p><p name="5edd" id="5edd" class="graf graf--p graf-after--p">We tried countless of different approaches to solving these problems. It ranged from writing detailed training documents, curating golden label datasets ourselves, ranking and rotating labellers, experimenting with varying mechanisms of filtering, etc. <strong class="markup--strong markup--p-strong">Though we did make progress, there was no single silver bullet.</strong></p><h3 name="be88" id="be88" class="graf graf--h3 graf-after--p">Labelling — It’s not about the Infra</h3><p name="573a" id="573a" class="graf graf--p graf-after--h3">There are a lot of tools to make labelling simpler. Platforms like <a href="https://www.mturk.com/" data-href="https://www.mturk.com/" class="markup--anchor markup--p-anchor" rel="noopener noreferrer nofollow noopener" target="_blank">Amazon’s Mechanical Turk</a> or <a href="https://cloud.google.com/ai-platform/data-labeling/pricing" data-href="https://cloud.google.com/ai-platform/data-labeling/pricing" class="markup--anchor markup--p-anchor" rel="noopener noreferrer nofollow noopener" target="_blank">Google’s AI Platform Data Labeling Service</a> provide infrastructure to streamline annotation pipelines and gather human labels, which can be integrated with various downstream MLOps services (e.g. continuous re-training and re-testing).</p><p name="14a7" id="14a7" class="graf graf--p graf-after--p">With that said, the process of label collection is non-trivial.</p><ol class="postList"><li name="69b5" id="69b5" class="graf graf--li graf-after--p"><strong class="markup--strong markup--li-strong">Example preparation</strong>. A good set of real or simulated examples needs to be prepared and collected so they are a good use of the labeller’s time. For example, asking if a car is at risk when driving straight, under the speed limit, with no one around is pointless.</li><li name="1f8f" id="1f8f" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Question Design</strong>. The right question needs to be asked so it is useful in training or reinforcing the model. For example, should there be a scale of the situation’s risk or a true/false or multiple-choice question? Should there be an open-ended text field that explains the risk? This requires iteration and experimentation. For reference, I find the <a href="https://openai.com/research/learning-from-human-preferences" data-href="https://openai.com/research/learning-from-human-preferences" class="markup--anchor markup--li-anchor" rel="noopener noreferrer nofollow noopener" target="_blank">question design OpenAI did for backflips</a> brilliant.</li><li name="5b67" id="5b67" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Labeler Training</strong>. Lablers need to be trained to understand what’s being asked and the expectation of what/how they should be answering.</li><li name="ee3e" id="ee3e" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Label Filtering.</strong> Even highly trained labellers make mistakes, and these outliers need to be filtered out from the dataset.</li><li name="abf5" id="abf5" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Labeling Fatigue</strong>. Manual labelling is a boring and tedious task. So it’s understandable that label quality will drop as the quantity from any single individual increases.</li><li name="50f5" id="50f5" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Subjectivity</strong>. The hard questions are the subjective ones. For example, asking whether an on-road situation is risky depends on personal preferences/biases (e.g. age, driving experience, personality, etc.) and cultural ones (e.g. US vs India).</li></ol><figure name="c05d" id="c05d" class="graf graf--figure graf-after--li"><img class="graf-image" data-image-id="0*_vTD6CT9OlFZRCmZ.png" data-width="1200" data-height="333" src="https://cdn-images-1.medium.com/max/800/0*_vTD6CT9OlFZRCmZ.png"><figcaption class="imageCaption"><a href="https://twitter.com/data36_com/status/1098220523811729408" data-href="https://twitter.com/data36_com/status/1098220523811729408" class="markup--anchor markup--figure-anchor" rel="noopener noreferrer nofollow noopener noopener" target="_blank">@data36_com</a></figcaption></figure><h3 name="8127" id="8127" class="graf graf--h3 graf-after--figure">OpenAI — Ahead of the Game</h3><p name="432e" id="432e" class="graf graf--p graf-after--h3">Everything I’ve said up until now isn’t news to the team at OpenAI.</p><p name="7085" id="7085" class="graf graf--p graf-after--p">In an <a href="https://openai.com/research/learning-from-human-preferences" data-href="https://openai.com/research/learning-from-human-preferences" class="markup--anchor markup--p-anchor" rel="noopener noreferrer nofollow noopener" target="_blank">article from June 2017</a>, where they first mentioned the use of RLHF, they were already aware of this problem:</p><blockquote name="b958" id="b958" class="graf graf--blockquote graf-after--p"><em class="markup--em markup--blockquote-em">Our algorithm’s performance is only as good as the human evaluator’s intuition about what behaviors </em>look<em class="markup--em markup--blockquote-em"> correct, so if the human doesn’t have a good grasp of the task they may not offer as much helpful feedback.</em></blockquote><p name="4f34" id="4f34" class="graf graf--p graf-after--blockquote">And in <a href="https://openai.com/research/instruction-following#sample1" data-href="https://openai.com/research/instruction-following#sample1" class="markup--anchor markup--p-anchor" rel="noopener noreferrer nofollow noopener" target="_blank">January of 2022</a>, they presented the flow that showed promising results in aligning language models to follow instructions</p><figure name="bef4" id="bef4" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="0*nT5wkioZeYn-P__R.png" data-width="1456" data-height="865" src="https://cdn-images-1.medium.com/max/800/0*nT5wkioZeYn-P__R.png"><figcaption class="imageCaption"><a href="https://openai.com/research/instruction-following#sample1" data-href="https://openai.com/research/instruction-following#sample1" class="markup--anchor markup--figure-anchor" rel="noopener" target="_blank">https://openai.com/research/instruction-following#sample1</a></figcaption></figure><p name="e2e2" id="e2e2" class="graf graf--p graf-after--figure">They did highlight that this issue was not entirely eliminated:</p><blockquote name="2ac5" id="2ac5" class="graf graf--blockquote graf-after--p"><em class="markup--em markup--blockquote-em">Further, in many cases aligning to the average labeler preference may not be desirable. For example, when generating text that disproportionately affects a minority group, the preferences of that group should be weighted more heavily. Right now, InstructGPT is trained to follow instructions in English; thus, it is biased towards the cultural values of English-speaking people.</em></blockquote><p name="ef4e" id="ef4e" class="graf graf--p graf-after--blockquote">OpenAI is doing their best to develop and iterate in public, and I hope they’ll extend their <a href="https://platform.openai.com/docs/guides/fine-tuning" data-href="https://platform.openai.com/docs/guides/fine-tuning" class="markup--anchor markup--p-anchor" rel="noopener noreferrer nofollow noopener" target="_blank">fine-tuning APIs</a> to GPT4 this year. However, this doesn’t solve the problem that the labels still need to be of high quality. <strong class="markup--strong markup--p-strong">We are past the era of “data quantity” and are now in the age of “data quality.”</strong></p><h3 name="7a68" id="7a68" class="graf graf--h3 graf-after--p">Nothing At Stake</h3><p name="8d0d" id="8d0d" class="graf graf--p graf-after--h3">One of the core problems solved by Proof-of-Stake blockchains is the <a href="https://vitalik.ca/general/2017/12/31/pos_faq.html#what-is-the-nothing-at-stake-problem-and-how-can-it-be-fixed" data-href="https://vitalik.ca/general/2017/12/31/pos_faq.html#what-is-the-nothing-at-stake-problem-and-how-can-it-be-fixed" class="markup--anchor markup--p-anchor" rel="noopener noreferrer nofollow noopener" target="_blank"><em class="markup--em markup--p-em">Nothing At Stake</em></a> problem. In short, an actor with some upside and zero downside has more incentive to perform low-quality or malicious work. [1]</p><p name="3968" id="3968" class="graf graf--p graf-after--p">Companies usually pay out annual bonuses at the end of the year, and occasionally need to restructure based on performance. Similarly, labelers get paid based on the amount of work they do and might be rotated to a different project if their labeling quality does not meet a specific bar.</p><p name="2477" id="2477" class="graf graf--p graf-after--p">Consider if companies were to pay out annual bonuses at the beginning of the year but take back part, or more, of it at the end of the year? Similarly, what if labelers were to lose a deposit for doing a poor job at annotating?</p><p name="63f3" id="63f3" class="graf graf--p graf-after--p">The concept is relatively straightforward and follows patterns from <a href="https://en.wikipedia.org/wiki/Prediction_market" data-href="https://en.wikipedia.org/wiki/Prediction_market" class="markup--anchor markup--p-anchor" rel="noopener noreferrer nofollow noopener" target="_blank">Prediction Markets</a>:</p><ol class="postList"><li name="53af" id="53af" class="graf graf--li graf-after--p">Labelers put down a deposit before doing any work</li><li name="fd1c" id="fd1c" class="graf graf--li graf-after--li">The experimenter prepares a list of tasks and puts a deposit that’ll split amongst all the labellers doing the work</li><li name="d47b" id="d47b" class="graf graf--li graf-after--li">The labellers finish their tasks</li><li name="3b2f" id="3b2f" class="graf graf--li graf-after--li">Labellers close to the mean (i.e. the general population) get a small payout from the experimenter</li><li name="5099" id="5099" class="graf graf--li graf-after--li">Labellers far from the mean don’t earn or lose anything</li><li name="30b7" id="30b7" class="graf graf--li graf-after--li">Outliers lose a portion of their deposit</li></ol><figure name="da75" id="da75" class="graf graf--figure graf-after--li"><img class="graf-image" data-image-id="0*iTogMEM__74FYHl5.png" data-width="576" data-height="455" src="https://cdn-images-1.medium.com/max/800/0*iTogMEM__74FYHl5.png"></figure><p name="9022" id="9022" class="graf graf--p graf-after--figure">An illustrative example outputted by a Python program generated by ChatGPT</p><p name="d625" id="d625" class="graf graf--p graf-after--p">It’s worth noting that this is not an original idea. [2] Two projects I was excited about in the earlier days of Ethereum were <a href="https://augur.net/" data-href="https://augur.net/" class="markup--anchor markup--p-anchor" rel="noopener noreferrer nofollow noopener" target="_blank">Augur</a> and <a href="https://www.gnosis.io/" data-href="https://www.gnosis.io/" class="markup--anchor markup--p-anchor" rel="noopener noreferrer nofollow noopener" target="_blank">Gnosis</a>, leveraging ideas from the <a href="https://www.goodreads.com/book/show/68143.The_Wisdom_of_Crowds" data-href="https://www.goodreads.com/book/show/68143.The_Wisdom_of_Crowds" class="markup--anchor markup--p-anchor" rel="noopener noreferrer nofollow noopener" target="_blank">Wisdom of the Crowds</a> through public and permissionless prediction markets.</p><h3 name="5fba" id="5fba" class="graf graf--h3 graf-after--p">Where do Blockchains fit in?</h3><p name="3f55" id="3f55" class="graf graf--p graf-after--h3">You might ask why this even needs a blockchain, and if you’re snarky, point me to this image:</p><figure name="480f" id="480f" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="0*ZY1uDcmV2INHOWr7.png" data-width="1060" data-height="610" src="https://cdn-images-1.medium.com/max/800/0*ZY1uDcmV2INHOWr7.png"><figcaption class="imageCaption"><a href="https://circo.io/gigo/" data-href="https://circo.io/gigo/" class="markup--anchor markup--figure-anchor" rel="noopener noreferrer nofollow noopener noopener" target="_blank">https://circo.io/gigo/</a></figcaption></figure><p name="4fe5" id="4fe5" class="graf graf--p graf-after--figure">Suppose we focus solely on product and do not consider institutional or geopolitical censorship. In that case, I can steelman the case for why we could build this as a traditional web2 SaaS. However, there are a handful of primitives in the Crypto industry which make it a good contender as the platform to build on.</p><ol class="postList"><li name="5f3f" id="5f3f" class="graf graf--li graf-after--p"><strong class="markup--strong markup--li-strong">Money is a first-class citizen</strong>. Depositing, earning and slashing are core primitives of any blockchain, making things like value transfer and micropayments cheaper and simpler.</li><li name="3fc4" id="3fc4" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Permissionless Identity</strong>. It is easy to sign up and participate regardless of where you are, keeping your identity optionally private. It also enables longer-term reputation-building mechanisms.</li><li name="431e" id="431e" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Commit &amp; Reveal paradigms</strong>. All the labels will be encrypted and public until the experiment is complete, so it’s hard to aim to be close to the mean unless users collude offline. No central party can game the results. [3]</li><li name="f76d" id="f76d" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Zero Knowledge Technology</strong>. A lot is being done in the zk space which can be utilized here. For example, the tasks could be designed so that the experimenter only gets the final results without being able to tie a label to any single user, while still enabling an ongoing reputation system. Alternatively, the labels could be completely hidden from everyone but still be used in reinforcement learning by leveraging <a href="https://fhe.org/" data-href="https://fhe.org/" class="markup--anchor markup--li-anchor" rel="noopener noreferrer nofollow noopener" target="_blank">fully homomorphic encryption</a>; <em class="markup--em markup--li-em">note that this is not easy.</em></li><li name="3c81" id="3c81" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Distributed Ledger Technology</strong>. Anyone can design a set of labelling tasks or sign up as a labeller. Depending on the type of encryption, it could also enable downstream use cases, such as data markets.</li></ol><figure name="dfad" id="dfad" class="graf graf--figure graf-after--li"><img class="graf-image" data-image-id="0*1ow2dBgXD0G8IDdS.png" data-width="1456" data-height="632" src="https://cdn-images-1.medium.com/max/800/0*1ow2dBgXD0G8IDdS.png"><figcaption class="imageCaption">Created by the author</figcaption></figure><h3 name="938e" id="938e" class="graf graf--h3 graf-after--figure">Tuning User Interfaces (TUIs)</h3><p name="8539" id="8539" class="graf graf--p graf-after--h3">While some things like math and science are objective and true, others, such as <em class="markup--em markup--p-em">safe</em> driving patterns, are nuanced and vary depending on the context. You might imagine how this extends to even more difficult political topics.</p><p name="58ad" id="58ad" class="graf graf--p graf-after--p">I don’t believe a single model will be able to satisfy everyone’s preferences, but fine-tuning a base model will. This will require a minimum number of labels, but will heavily rely on their quality moreso than their quantity.</p><p name="4e07" id="4e07" class="graf graf--p graf-after--p">Bill Gates called this the largest technological innovation he has seen <a href="https://www.gatesnotes.com/The-Age-of-AI-Has-Begun" data-href="https://www.gatesnotes.com/The-Age-of-AI-Has-Begun" class="markup--anchor markup--p-anchor" rel="noopener noreferrer nofollow noopener" target="_blank">since the GUI</a>, and Stephen Wolfram has <a href="https://writings.stephenwolfram.com/2023/03/will-ais-take-all-our-jobs-and-end-human-history-or-not-well-its-complicated/" data-href="https://writings.stephenwolfram.com/2023/03/will-ais-take-all-our-jobs-and-end-human-history-or-not-well-its-complicated/" class="markup--anchor markup--p-anchor" rel="noopener noreferrer nofollow noopener" target="_blank">dubbed new chat interfaces</a> as Linguistic User Interfaces (LUIs). I’m suggesting we also need to think about Tuning User Interfaces (TUIs), so our models can age with us like a fine wine. 🍷</p><p name="b29f" id="b29f" class="graf graf--p graf-after--p graf--trailing">Subscribe if reading this was a good use of your time :)</p></div></div></section><section name="7053" class="section section--body section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h3 name="50e8" id="50e8" class="graf graf--h3 graf--leading">Appendix</h3><p name="ecb2" id="ecb2" class="graf graf--p graf-after--h3">[1] An actor in a network that is responsible to provide a certain service (e.g. securing a blockchain, making data available, etc…) must put up a deposit that is subject to penalties (i.e. slashed/burnt) if they are proven to be faulty or malicious. Rather than just having the upside of earning money for providing a service, they also face the consequences of a negative ROI.</p><p name="ba55" id="ba55" class="graf graf--p graf-after--p">From my experience, labellers are exposed to the upside of labelling more examples, but the only downside they face is being removed from a certain labelling task if their label quality score becomes too low. By introducing <a href="https://en.wikipedia.org/wiki/Loss_aversion" data-href="https://en.wikipedia.org/wiki/Loss_aversion" class="markup--anchor markup--p-anchor" rel="noopener noreferrer nofollow noopener" target="_blank">Loss Aversion</a> (the psychological pain of losing is twice as powerful as the pleasure of gaining) along with the <a href="https://en.wikipedia.org/wiki/Endowment_effect" data-href="https://en.wikipedia.org/wiki/Endowment_effect" class="markup--anchor markup--p-anchor" rel="noopener noreferrer nofollow noopener" target="_blank">Endowment Effect</a> (an individual’s places a higher value on something they already have), I believe the quality of labels can be much higher.</p><p name="c562" id="c562" class="graf graf--p graf-after--p">[2] Most good ideas are just regurgitations of existing ideas executed on by the right team at the right time. <a href="https://vitalik.ca/general/2022/12/05/excited.html" data-href="https://vitalik.ca/general/2022/12/05/excited.html" class="markup--anchor markup--p-anchor" rel="noopener noreferrer nofollow noopener" target="_blank">Vitalik’s comment</a> captures it well:</p><blockquote name="38e8" id="38e8" class="graf graf--blockquote graf-after--p"><em class="markup--em markup--blockquote-em">Today, enough time has passed that there are few ideas that are completely unexplored: if something succeeds, it will probably be some version of something that has already been discussed in blogs and forums and conferences on multiple occasions</em></blockquote><p name="58a5" id="58a5" class="graf graf--p graf-after--blockquote graf--trailing">[3] The perceptive reader might raise the issue of Sybil Attacks. Though this is a fair consideration, a well-designed stake &amp; burn mechanism can deter this.</p></div></div></section>
</section>
<footer><p><a href="https://medium.com/p/b65cfebb8329">View original.</a></p><p>Exported from <a href="https://medium.com">Medium</a> on September 13, 2025.</p></footer></article></body></html>